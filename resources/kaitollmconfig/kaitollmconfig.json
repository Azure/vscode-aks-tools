{
    "name": "Kaito LLM Model Config",
    "version": "1.0",
    "modelsupported": {
        "falcon": ["falcon-7b-instruct", "falcon-7b", "falcon-40b-instruct", "falcon-40b"],
        "llama2": ["llama2-7b", "llama2-13b", "llama2-70b"],
        "llma2chat": ["llama2-7b-chat", "llama2-13b-chat", "llama2-70b-chat"],
        "mistral": ["mistral-7b-instruct", "mistral-7b"],
        "phi-2": ["phi-2"],
        "phi-3": ["phi-3-mini-4k-instruct", "phi-3-mini-128k-instruct", "phi-3-mini-4k-instruct", "phi-3-mini-128k-instruct"]
    },
    "docref": "https://github.com/Azure/kaito/blob/main/presets/models/supported_models.yaml"
}